---
title: "Computational Thinking with SIR Models"
subtitle: "A Disease Ecology Module"
engine: knitr
format:
  live-html:
    fig-align: "center"
    toc: true
    toc-location: right
    toc-depth: 4
    code-fold: false
    code-tools: true
    theme: cosmo
    number-sections: true
bibliography: ../reference.bib
webr:
  packages:
    - pracma
    - bbmle
    - dplyr
---

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}

# Introduction and Course Learning Objectives

# Introduction and The Classic Epidemic Model


## Epidemiology Terms {#sec-epidemiology-terms}

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Define basic terms in epidemiology.
:::

For the purposes of mathematical models in epidemiology, such as the SIR model, individuals are classified based solely on their ability to transmit a pathogen, not their diseased status (whether or not they exhibit symptoms). For the purposes of epidemiological models, individuals are generally classified into four primary categories:

-   **Susceptible:** No pathogen is present in the individual. The individual only has a low level of non-specific immunity to incoming infection.

-   **Exposed:** The individual has encountered an infected individual and is infected with the pathogen. The levels of pathogen in this individual are too low to allow them to transmit the disease to another person. This individual is hence considered "exposed" to the pathogen but not yet able to infect others with it.

-   **Infectious:** The individual has surpassed the exposed stage and the pathogen levels within them are high enough to allow for transmission. This individual is no longer just exposed to the pathogen, but can actively spread it now.

-   **Recovered:** The individual has surpassed the infectious stage, their immune system has cleared enough of the pathogen that they can no longer transmit it. This individual has some amount of immunity to the pathogen now, but for how long this immunity lasts depends on the specific pathogen.

::: {.callout-note}
The individual can still exhibit symptoms of the disease while in the recovered compartment, so it is best to think of this compartment as individuals who have "recovered" from their ability to spread the infection but not necessarily all symptomatic implications of that infection.
:::

These categories are not exhaustive, and individuals can be classified into further categories based on their stage of infection or immunity status, just to name a few. These four categories are highlighted since they come up most often while discussing SIR-type models and epidemiological models in general. It is important to note that, at the same time individuals fall into these categories, they can also be classified based on whether or not they exhibit symptoms of infection:

-   **Incubation Period:** The individual has been infected with the pathogen but does not show disease symptoms. This is also commonly refferred to as the *asymptomatic period*.

-   **Diseased period:** The individual has surpassed the incubation period and begins to show symptoms of the disease.

Although these classifications are more commonly used in a medical, rather than an epidemiological, contexts, we still provide them here to clarify the fact that an individual can still be infectious while in the incubation period and showing no symptoms of the disease. Similarly, an individual can still be in the diseased period and show lingering symptoms of infection while being recovered since their immune system has cleared enough of the pathogen that they are not longer infectious.

(PLACE GRAPH HERE OF ALL THESE PERIODS)

**Section References**

@keeling_modeling_2008

## Introducing Compartmental Models {#sec-introducing-compartmental-models}

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Define what a compartmental model is.
-   Identify which differential equation models can be called compartmental models.
:::

Generally speaking, compartmental models are a way to represent the flow of populations between different states, known as compartments, using differential equations. Compartmental models show up in a wide variety of fields, not just epidemiology. Any field that can benefit from knowing how information flows between states can benefit from compartmental models.

In the epidemiological context, compartmental models are analyzing how people flow through the four categories, which will be referred to simply as "compartments" from now on, introduced in [Section @sec-epidemiology-terms]: susceptible (S), exposed (E), infectious (I), and recovered (R). The relationships between these compartments are often represented using flowcharts like the one seen below.


```{dot}
//| fig-width: 8
//| fig-height: 2
//| fig-align: center


digraph SEIR {
  rankdir=LR;
  node [shape=box, style=rounded, fontsize=14];

  S [label="S"];
  E [label="E"];
  I [label="I"];
  R [label="R"];

  edge [fontsize=12];
  S -> E [label="λ", labelfontsize=12, labeldistance=2.0, labelangle=-90];
  E -> I [label="σ", labelfontsize=12, labeldistance=2.0, labelangle=-90];
  I -> R [label="γ",  labelfontsize=12, labeldistance=2.0, labelangle=-90];
}
```

The arrows between these compartments represent the direction of flow (susceptible individuals becoming exposed, exposed individuals becoming infectious, etc.) and the symbols above each arrow represent the *flow rates* between each compartment with respect to time.

It's easiest to understand this conceptually through an example. Say in a very large population with the established presence of a pathogen, on average, 300 new people become exposed to a pathogen every day. Of those that are exposed to the pathogen, on average, 50 of them reach pathogen levels high enough to become infectious per day. Then, of those that are infectious and able to transmit the pathogen, on average, 40 of them recover from the pathogen (in the sense that they can no longer transmit it). We can model this specific example with the modified flowchart below:


```{dot}
//| fig-width: 8
//| fig-height: 2
//| fig-align: center


digraph SEIRmod {
  rankdir=LR;
  node [shape=box, style=rounded, fontsize=14];

  S [label="S"];
  E [label="E"];
  I [label="I"];
  R [label="R"];

  edge [fontsize=12];
  S -> E [label="λ = 300", labelfontsize=12, labeldistance=2.0, labelangle=-90];
  E -> I [label="σ = 50", labelfontsize=12, labeldistance=2.0, labelangle=-90];
  I -> R [label="γ = 40",  labelfontsize=12, labeldistance=2.0, labelangle=-90];
}
```

Which compartments we choose to include depends on the specific pathogen and disease we are modeling. Models where the exposed period is so small it can be considered negligible, or is ommited for the sake of simplicity, are specifically known as *SIR models* (standing for the three different compartments included in the model: susceptible, infectious, and recovered).

::: {.callout-note}
Some sources will refer generally to any compartmental epidemiological model as an "SIR model," but in our context we will make the distinction between SIR models and models that include different compartments than just susceptible, infectious, and recovered.

We will, however, refer to the general idea of compartmental epidemiological models as "SIR-type models."
:::

[Section @sec-the-classic-sir-epidemic-model] covers the specific formulation and assumptions of this model.

**Section References**

@keeling_modeling_2008

## The Classic SIR Epidemic Model {#sec-the-classic-sir-epidemic-model}

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Recall the classic epidemic model's equations.

-   Construct equations for novel compartmental models given the flow rates between each of the compartments.

-   Identify the assumptions (and their justifications) made in the formulation of the classic epidemic model, including the assumptions made in relation to how its parameters were obtained / formulated.

-   Recall what parameters go into the construction of the classic epidemic model, including the typical symbols for each.

-   Explain how the classic epidemic model deviates from reality in relation to the assumptions it makes.

-   Differentiate situations where an empirically deduced transmission rate is more accurate and beneficial to one calculated based on first principles.

-   Discern what situations are best modeled by frequency or density dependent transmission rates, or a combination of both.
:::

The classic SIR epidemic model is a type of compartmental model that makes the following key assumptions:

1.  The epidemic invades the population and concludes itself quickly enough that demographic processes, namely births and deaths, are not very influential to the overall process and can be omitted from the model. This is also known as the *closed population* assumption.

2.  Individuals move between the compartments of susceptible, infectious, and recovered only. Other compartments, namely the exposed compartment, are omitted for simplicity.

::: {.callout-note}
Since this module covers only the epidemic and endemic SIR models, neither of which include the exposed compartment, the terms "infected" and "infectious" will be used interchangeably moving forward. This is because with only the susceptible, infectious, and recovered compartments, once an individual gets infected with the pathogen we assume they are infectious as well.

It is important to note that although "infected" and "infectious" are used interchangeably within the context of this learning module, they are not synonymous all the time. As model complexity increases and the exposed compartment is included, a distinction must be made between the two, as an individual can be considered "infected" but not "infectious" (i.e. they belong to the exposed compartment).
:::

These are not the only assumptions made by the epidemic SIR model, but they do clearly distinguish it from other compartmental models such as the SEIR model, which includes exposed compartment, and the endemic SIR model, which includes the flow in and out of each compartment due to demographics (births and death).

Moving forward, $S$. $I$, and $R$ will refer to the *number* of individuals in the susceptible, infectious, and recovered compartments, respectively. The variables $\tilde{S}=\frac{S}{N}$, $\tilde{I}=\frac{I}{N}$, and $\tilde{R}=\frac{webr}{N}$, will be used to refer to the *proportion* of individuals in the susceptible, infectious, and recovered compartments, respectively, where $N$ is the total number of individuals in the population defined as $N=S+I+R$.

::: {.callout-note}
-   Since the epidemic model assumes a closed population with no births or deaths, $N$ is not a variable that can change but a constant.

-   Notice that $\tilde{S}+\tilde{I}+\tilde{R}=1$
:::

The following equations provide the rates of change, with respect to time, for the number of individuals in each of the three compartments of the epidemic SIR model:

$$
\begin{aligned}
\frac{dS}{dt} &= -\lambda S \\[10pt]
\frac{dI}{dt} &= \lambda S - \gamma I \\[10pt]
\frac{dR}{dt} &= \gamma I
\end{aligned}
$$

Dividing each equation by the population size $N$, we can rewrite the SIR equations above to provide the rates of change, with respect to time, for the proportion of individuals in each compartment:

$$
\begin{aligned}
\frac{d\tilde{S}}{dt} &= -\lambda \tilde{S} \\[10pt]
\frac{d\tilde{I}}{dt} &= \lambda \tilde{S} - \gamma \tilde{I} \\[10pt]
\frac{d\tilde{R}}{dt} &= \gamma \tilde{I}
\end{aligned}
$$

::: {.callout-note}
The rate of change of the number of people in each compartment can be understood as following the basic pattern of $R_i-R_o$ where $R_i$ is the rate that people are flowing into the compartment per unit time and $R_o$ is the rate that people are flowing out of the compartment per unit time. This pattern can be used to construct any number of novel compartmental models.
:::

Notice that these equations mirror exactly the compartmental flowcharts introduced in the [Section @sec-introducing-compartmental-models]. The epidemic SIR model can be representing with the following flowchart:


```{dot}
//| fig-width: 8
//| fig-height: 1
//| fig-align: center


digraph SIRepi {
  rankdir=LR;
  node [shape=box, style=rounded, fontsize=14];

  S [label="S"];
  I [label="I"];
  R [label="R"];

  edge [fontsize=12];
  S -> I [label="λ", labelfontsize=12, labeldistance=2.0, labelangle=-90];
  I -> R [label="γ",  labelfontsize=12, labeldistance=2.0, labelangle=-90];
}
```

The flow rates between each compartment have specific names and symbology, summarized in the table below:

| **Terminology / Name** | **Common Symbol** | **Interpretation** |
|-------------------|------------------|-----------------------------------|
| Force of Infection | $\lambda$ | The per capita rate at which susceptible individuals are becoming infectious per unit time. |
| Recovery Rate | $\gamma$ | The per capita rate at which infectious individuals are recovering from infection per unit time. |

::: {.callout-note}
The phrase "per capita" here refers to a rate that is divided among each person in the given compartment. Take the following example: if 3 people are pouring water into a large bucket and each are adding 5 cups per minute, then the per capita rate at which water is being added is 5 cups per minute. To obtain the total rate at which water is being poured into the bucket, we would multiply the number of people pouring, 3, by their per capita rate, 5, to get a total inflow of 15 cups per minute.

A similar logic is being utilized in the SIR equations: the number of susceptible people at a given time, $S$, is multiplied by the per capita rate they are becoming infectious to get the total rate at which people are entering the infectious compartment Similarly, the number of infectious people at a given time, $I$, is multiplied by the per capita rate they are recovering to get the total rate at which people are entering the recovered compartment
:::

**Section References**

@keeling_modeling_2008

### Formulating the Force of Infection {#sec-formulating-foi}

The force of infection, or the rate at which susceptible individuals are becoming infected per unit time, can be understood and formulated based on first principles in epidemiology as follows:

> Consider the perspective of a susceptible individual in the population at any given time. Let's say this individual makes, on average, $c$ contacts with other people per unit time. Then, suppose that of those $c$ people this individual makes contact with per unit time, the proportion of them that will be infectious is $\tilde{I}$. Then, of those $c\tilde{I}$ contacts this individual makes with infectious people, the proportion of them that will actually succeed at spreading the infection to them is $p$. Multiplying these together, we can obtain the per capita (per person) rate which susceptible people are becoming infectious, or the force of infection as follows: $$
> \lambda=cp\tilde{I}
> $$

::: {.callout-note}
Although this formulation for $\lambda$ is based on first principles, there are still a number of assumptions being made. Namely:

1.  We assume every individual in the population comes into contact with other individuals at a constant rate $c$. This means we assume everyone in the population is equally sociable and, on average, comes into contact with the same number of people per unit time.

2.  We assume *homogeneous mixing* of the population. That is, we assume everyone has an equal probability of contacting any other individual in the population. In real life, this is of course not true: infectious individuals are more likely to come into contact with other infectious individuals if they go to the hospital and are less likely to come into contact with susceptible individuals if they quarantine, just to name a few examples.
:::

The force of infection is calculated in many ways; we just provide one of many possible formulations and rationales here. Notice that the terms $c$ and $p$ in the formulation of $\lambda$ are independent of the number of individuals in each compartment throughout time. For this reason, they are grouped together into a singular term, known as the *transmission rate*.

Putting this all together, we can rewrite the SIR model equations from [Section @sec-the-classic-sir-epidemic-model] as follows:

$$
\begin{aligned}
\frac{dS}{dt} &= -\beta \tilde{I} S \\[10pt]
\frac{dI}{dt} &= \beta \tilde{I} S - \gamma I \\[10pt]
\frac{dR}{dt} &= \gamma I
\end{aligned}
$$

And for proportions:

$$
\begin{aligned}
\frac{d\tilde{S}}{dt} &= -\beta \tilde{I} \tilde{S} \\[10pt]
\frac{d\tilde{I}}{dt} &= \beta \tilde{I} \tilde{S} - \gamma \tilde{I} \\[10pt]
\frac{d\tilde{R}}{dt} &= \gamma \tilde{I}
\end{aligned}
$$

Now comes the question of how we even find $\beta$? The table below presents two common methods for calculating $\beta$:

| **Method** | **What is it?** | **Best Used When . . .** |
|------------------|----------------------------------|---------------------|
| Blackbox method | This is a data-driven method wherein $\beta$ is calculated empirically using epidemiological data. We can think of this as "fitting" a value of $\beta$ in our model to most accurately reflect the dynamics we observe in the real world. | There is an abundance of accurate real-world data available on the number of susceptible and infectious people over time. |
| First-Principles method | This method utilizes the formulation $\beta=cp$, which was obtained using first-principles, and separately calculates appropriate values for $c$ and $p$. | Real-world data is scarcer or there the data available lends itself better to calculating $c$ and $p$ separately rather than fitting an overall $\beta$. |


For the purposes and scope of this introductory module, we will only provide examples and insights into the blackbox method for calculating the transmission rate $\beta$. This is because specifics of how $c$ and $p$ are calculated using the first-principles method depends heavily on model context and complexity, meaning there is no "one size fits all" way of finding $\beta$ using this method. 

Models will often formulate $c$ and $p$ as functions of their own depending on a number of external variables. An example of this can be found in this paper [@deer_covid], where the transmission rate $\beta$ is formulated as the product of the proximity rate $\omega_{ij}$, or "frequency per day that host $i$ and recipient $j$ are within 1.5 meters (m) of each other" and $\sigma^{Aero}$, or the "probability of infection from aerosols." The paper further decomposes $\omega_{ij}$ and $\sigma^{Aero}$ into functions of their own depending on a variety of external variables. 

The specific formulations for the contact rate (or proximity rate) and infection probability utilized by this paper are unique to its context (the pathogen it is analyzing, the host population(s), etc.) and will vary widely from paper to paper. PROVIDE CITATIONS FOR MORE EXAMPLES OF DIFFERENT BETA CALCULATIONS HERE. 

However, there are standardized procedures to obtain $\beta$ using the blackbox approach, of which one common method known as *maximum likelihood estimation*, or MLE for short, is covered in [Section @sec-formulating-transmission-rate]. But before we can cover MLE, we must go over how to solve our SIR model equations first, which is the topic of [Section @sec-solving-sir-equations].  

### Formulating the Recovery Rate {#sec-formulating-the-recovery-rate}

In the classic epidemic SIR model, there are only two parameters we must estimate: the transmission rate $\beta$ and the recovery rate $\gamma$. In [Section @sec-formulating-foi], we introduce the blackbox and first-principles approach for estimating the value of $\beta$. 

The other parameter we must estimate---the recovery rate---is often estimated based on prior literature instead of real-world data like $\beta$. The reason for this is because $\beta$ is heavily dependent on many real-world factors like population density, demographics, and public-health measures, all of which vary greatly depending on the context of the model. The recovery rate, on the other hand, is often formulated as simply the reciprocal of the average duration of infection and thus is considered to be "more stable compared with $\beta$" [@parameter_estimation]. 

:::{.callout-note}
When we say the recovery rate is 'more stable' than the transmission rate, we are simply saying that it varies less based on disease context and it stays relatively constant over the course of the epidemic.

To illustrate just how differently disease contexts affect $\beta$ and $\gamma$, suppose the following two situations: we have a measles outbreak in a city that mandates sick individuals wear masks and quarantine themselves of a week and another measles outbreak in a rural town with very little control measures. We would expect the transmission rate for the city with high control measures to be much lower than the transmission rate for the rural town since infectious people in the city are interacting less with individuals (due to the quarantine mandate) and are less likely to spread the disease from those interactions (due to the mask mandates) compared to the rural town. However, we would expect the recovery rate in these two contexts to be approximately the same as sick people in the city will, on average, be infectious for the same amount of time as people in the rural town. 

We can think of the recovery rate as dependent on the biology of the disease itself whereas the transmission rate is dependent on context-specific factors. 
:::

To recap the methods of estimating our model parameters:

- Recovery rate ($\gamma$)
  - Literature Review: Estimated using past literature on the average duration of infection / infectious period $d$ and calculated as $\gamma=\frac{1}{d}$

- Transmission rate ($\beta$)
  - Blackbox Method: "Fitting" a suitable value of $\beta$ using real-world data from the scenario we are trying to model (i.e. finding which value of $\beta$ produces a model that describes what we see in the real-world most accurately)
  - First-Principles Method: Using a combination of real-world data and theory to produce estimates for the average contact rate $c$ and probability of infection $p$ separately and calculating the transmission rate as $\beta=cp$

The table below provides some empirically-deduced average infectious periods for various common diseases [@anderson_may_1982]:

| **Infectious Disease** 	| **Infectious Period (days)** 	|
|------------------------	|------------------------------	|
| Measles                	| 6 to 7                       	|
| Whooping cough         	| 21 to 23                     	|
| Poliomyelitis          	| 14 to 20                     	|
| Chicken pox            	| 10 to 11                     	|
| Rubella                	| 11 to 12                     	|
| Mumps                  	| 4 to 8                       	|
| Diphtheria             	| 14 to 21                     	|
| Scarlet fever          	| 14 to 21                     	|


## Solving SIR Equations {#sec-solving-sir-equations}

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Solve basic SIR model equations using a combination of mathematical and computational techniques.

-   Identify the difference between common methods of solving SIR-type models, including Euler's method and using function in the `pracma` package in R.
:::

Two common methods of solving differential equations that are difficult to solve by hand (in an exact method, that is) is:

1.  Euler's method
2.  The `pracma` package in R

We will go over each method in [Sections @sec-euler-method] and [@sec-pracma] and the differences between the two.

### Euler's method {#sec-euler-method}

Euler's method estimates the solution to a differential equation using a series of short, connected linear approximations at a discrete set of times. Although Euler's method is widely regarded to be a relatively inefficient method for solving otherwise "unsolvable" (at least in the elementary sense) ordinary differential equations, it is still valued for its simplicity and accessibility.

Suppose we have approximate initial values for the variables of interest (which, in the case of the SIR model, is the number or proportion of susceptible, infectious, and recovered individuals at the beginning of our study period). We will denote the number of susceptible, infectious, and recovered individuals at starting time $t$ as $S(0)$, $I(0)$, and $R(0)$, respectively.

::: {.callout-note}
To keep it simple, we will only discuss the process of Euler's method as it is applied to the number of individuals in each compartment, but keep in mind this process can be applied in exactly the same way to proportions as well.
:::

Our goal is to find an approximate solutions to $S(t)$, $I(t)$, and $R(t)$---the number of individuals in each compartment at time $t$---using $s(0)$, $i(0)$, and $r(0)$ and the rates of change given by the system of SIR equations formulated in [Section @sec-the-classic-sir-epidemic-model]. For clarity, $S(t)$, $I(t)$, and $R(t)$ represent the exact solutions to the SIR equations, and the approximation solutions given by Euler's method are represent as $s(t)$, $i(t)$, and $r(t)$.

::: {.callout-note}
These types of problems, one where we are given a set of intial values and corresponding differential equations, are known as initial-value problems (or IVPs).
:::

Euler's method involves repeatedly finding tangent line approximations to $S(t)$, $I(t)$, and $R(t)$ at a discrete set of times (often called nodes):

-   $s_0,\dots,s_t,\dots,s_b$
-   $i_0,\dots,i_t,\dots,i_b$
-   $r_0,\dots,r_t,\dots,r_b$

::: {.callout-note}
$s_t$, $i_t$, and $r_t$ represent approximations to $S(t)$, $I(t)$, and $R(t)$ at a time $t$. Additionally, $s_b$, $i_b$, and $r_b$ just represent the approximation at the final time $b$ of the interval we wish to find an approximate solution to, or $[0,b]$ .
:::

These approximations are found using the following recursive formulas:

$$
\begin{aligned}
s_{t+1} &= s_t - \Delta t \, \beta i_t s_t \\[10pt]
i_{t+1} &= i_t + \Delta t \, (\beta i_t s_t - \gamma i_t) \\[10pt]
r_{t+1} &= r_t + \Delta t \, \gamma i_t
\end{aligned}
$$

Where:

-   $s_{t+1}$, $i_{t+1}$, and $r_{t+1}$ are the approximations for $S(t)$, $I(t)$, and $R(t)$ at the next node
-   $s_{t}$, $i_{t}$, and $r_{t}$ are the approximations for $S(t)$, $I(t)$, and $R(t)$ at the previous node
-   $\Delta t$ is the step size (how far each node is spaced apart on the $t$-axis)
-   $\beta$ and $\gamma$ are the transmission and recovery rate, respectively

::: {.callout-note}
This formula is just an application of the generalized Euler's method for first-order differential equation $Y'(t)=f(t,Y(t))$, true solution $Y(t)$, and approximate solutions $y_0,\dots,y_t,\dots,y_b$, which are calculated at evenly spaced $t_n$ as:

$y_{t+1}=y_t+ \Delta t f(t_n,Y(t_n)$

Where again $\Delta t$ is how far each $t_n$ are apart.

Specifically, the formulas provided above substitute the rate of change functions $\frac{dS}{dt}$, $\frac{dI}{dt}$, and $\frac{dR}{dt}$ in directly.
:::

This process can be a little confusing to grasp at first, so let's do an example.

Suppose the following SIR model equations with initial values $s(0)=99$, $i(0)=1$, $r(0)=0$, transmission rate $\beta=1.5$, and recovery rate $\gamma=0.5$:

$$
\begin{aligned}
\frac{dS}{dt} &= -1.5 \tilde{I} S \\[10pt]
\frac{dI}{dt} &= 1.5 \tilde{I} S - 0.5 I \\[10pt]
\frac{dR}{dt} &= 0.5 I
\end{aligned}
$$

The following table illustrates the calculation process until $t=5$ with a step size of $\Delta t=1$:

| **Time** | **Approximations** | **Calculation Process** |
|-----------------|------------------------|-------------------------------|
| $t=0$ | $s\left(0\right)=99.0$<br>$i\left(0\right)=1.0$<br>$r\left(0\right)=0.0$ | — |
| $t=1$ | $s\left(1\right)\approx 97.5$<br>$i\left(1\right)\approx 2.0$<br>$r\left(1\right)=0.5$ | $s\left(1\right)=99-\left(1\right)\left(1.5\right)\left(\frac{1}{100}\right)\left(99\right)$<br>$i\left(1\right)=1+\left(1\right)\left[\left(1.5\right)\left(\frac{1}{100}\right)\left(99\right)-0.5\left(1\right)\right]$<br>$r\left(1\right)=0+\left(1\right)\left(0.5\right)\left(1\right)$ |
| $t=2$ | $s\left(2\right)\approx 94.6$<br>$i\left(2\right)\approx 3.9$<br>$r\left(2\right)\approx 2.0$ | $s\left(2\right)=97.5-\left(1\right)\left(1.5\right)\left(\frac{2.0}{100}\right)\left(97.5\right)$<br>$i\left(2\right)=2.0+\left(1\right)\left[\left(1.5\right)\left(\frac{2.0}{100}\right)\left(97.5\right)-0.5\left(2.0\right)\right]$<br>$r\left(2\right)=0.5+\left(1\right)\left(0.5\right)\left(2.0\right)$ |
| $t=3$ | $s\left(3\right)\approx 89.1$<br>$i\left(3\right)\approx 7.5$<br>$r\left(3\right)\approx 3.4$ | $s\left(3\right)=94.6-\left(1\right)\left(1.5\right)\left(\frac{3.9}{100}\right)\left(94.6\right)$<br>$i\left(3\right)=3.9+\left(1\right)\left[\left(1.5\right)\left(\frac{3.9}{100}\right)\left(94.6\right)-0.5\left(3.9\right)\right]$<br>$r\left(3\right)=2.0+\left(1\right)\left(0.5\right)\left(3.9\right)$ |
| $t=4$ | $s\left(4\right)\approx 79.1$<br>$i\left(4\right)\approx 13.7$<br>$r\left(4\right)\approx 7.2$ | $s\left(4\right)=89.1-\left(1\right)\left(1.5\right)\left(\frac{7.5}{100}\right)\left(89.1\right)$<br>$i\left(4\right)=7.5+\left(1\right)\left[\left(1.5\right)\left(\frac{7.5}{100}\right)\left(89.1\right)-0.5\left(7.5\right)\right]$<br>$r\left(4\right)=3.4+\left(1\right)\left(0.5\right)\left(7.5\right)$ |
| $t=5$ | $s\left(5\right)\approx 62.8$<br>$i\left(5\right)\approx 23.1$<br>$r\left(5\right)\approx 14.0$ | $s\left(5\right)=79.1-\left(1\right)\left(1.5\right)\left(\frac{13.7}{100}\right)\left(79.1\right)$<br>$i\left(5\right)=13.7+\left(1\right)\left[\left(1.5\right)\left(\frac{13.7}{100}\right)\left(79.1\right)-0.5\left(13.7\right)\right]$<br>$r\left(5\right)=7.2+\left(1\right)\left(0.5\right)\left(13.7\right)$ |

::: {.callout-tip title="Note"}
The accuracy of the solution produced by Euler's method is a direct result of what we choose the step size to be. If the step size is larger, then the curvature of the true solution will be lost since we are repeatedly taking linear approximations, resulting in an approximate solution that deviates a lot from the true solution curve. On the other hand, as the step size gets smaller, the approximate solution provided by Euler's method converges to the true solution curve.

See [Section @sec-evaluating-and-comparing-both-methods] for a simulation demonstrating what happens when you change the step size.
:::

As you might notice, the calculations above are very tedious, which is why Euler's method is most often calculated using code rather than by hand. Read on to [Section @sec-euler-code] for a demonstration on how to code Euler's Method.

#### Euler's Method Code Demonstration {#sec-euler-code}

This section contains a step by step walkthrough of how to code an Euler's Method algorithm in R. 

**Step 1: Define the biological parameters.**

Every model starts with its parameters: the biological quantities that characterize the disease and host system. Here, we have two: how fast the disease spreads ($\beta$) and how fast individuals recover ($\gamma$).

```{webr}
# Transmission rate: contacts × probability of transmission per unit time
beta <- 1.5

# Recovery rate: 1/gamma gives the average duration of infection
gamma <- 0.5

# With these values, the average infectious period is:
cat("Average infectious period:", 1/gamma, "time units")
```

---

**Step 2: Set the initial conditions.**

Before the model can run, we need to specify where the system starts. In an epidemic model, this means the proportion of the population in each compartment at time zero.

```{webr}
# Starting proportions — must sum to 1
S0 <- 0.99   # 99% susceptible: nearly everyone is susceptible at the start
I0 <- 0.01   # 1% infectious: a small "spark" of infection enters the population
R0_start <- 0.00   # 0% recovered: no prior immunity

# Verify they sum to 1 (a good sanity check to build into your code)
cat("S0 + I0 + R0 =", S0 + I0 + R0_start, "\n")
```

This sanity check, confirming that proportions sum to 1 — is a simple example of a habit that will save you debugging time later. When you add more compartments (SEIR, endemic model), this check generalizes naturally.

---

**Step 3: Set up the time grid.**

Euler's method steps through time discretely. We need to decide how far apart those steps are ($\Delta t$, the step size) and how long to simulate.

```{webr}
dt    <- 0.1   # step size — try making this larger later to see what breaks
t_end <- 50    # total simulation time

# Create a vector of all time points
times   <- seq(0, t_end, by = dt)
n_steps <- length(times)

cat("Number of time steps:", n_steps, "\n")
cat("Time points run from", times[1], "to", times[n_steps], "\n")
```

The step size is a computational choice, not a biological one, but it affects accuracy. A smaller $\Delta t$ gives a more accurate approximation of the continuous solution, at the cost of more computation. We will explore this tradeoff shortly.

---

**Step 4: Pre-allocate storage.**

Before running the loop, we create empty vectors to hold the results at each time step. This is more efficient than growing a vector inside the loop.

```{webr}
# Empty vectors: one slot per time step, filled with zeros for now
S <- numeric(n_steps)
I <- numeric(n_steps)
R <- numeric(n_steps)

# Fill in the starting values
S[1] <- S0
I[1] <- I0
R[1] <- R0_start

cat("Storage ready. First values: S =", S[1], " I =", I[1], " R =", R[1], "\n")
```

Think of these vectors as the model's memory: they store the entire trajectory of the epidemic, one row per time step.

---

**Step 5: Run the Euler loop.**

This is where the model actually runs. At each time step, we calculate the rates of change using the SIR equations and use them to update the compartment values. Each line in the loop maps directly to an equation.

```{webr}
for (t in 1:(n_steps - 1)) {

  # Rate of change: these ARE the SIR equations, written as code
  dS <- -beta * I[t] * S[t]                    # new infections leaving S
  dI <-  beta * I[t] * S[t] - gamma * I[t]     # gain infections, lose recoveries
  dR <-  gamma * I[t]                          # recoveries entering R

  # Step forward: current value + (step size × rate of change)
  S[t+1] <- S[t] + dt * dS
  I[t+1] <- I[t] + dt * dI
  R[t+1] <- R[t] + dt * dR
}

# Quick check: do the compartments still sum to 1 at the end?
cat("Final values: S =", round(S[n_steps], 4),
    " I =", round(I[n_steps], 4),
    " R =", round(R[n_steps], 4), "\n")
cat("Sum:", round(S[n_steps] + I[n_steps] + R[n_steps], 6), "\n")
```

The loop is doing exactly what the Euler update formulas say, mechanically, one step at a time. This is the computational equivalent of doing the hand calculations from the table shown earlier, just thousands of times faster.

---

**Step 6: Visualize the results.**

The vectors `S`, `I`, and `R` now hold the full epidemic trajectory. We can plot them against time.

```{webr}
plot(times, S, type = "l", col = "steelblue", lwd = 2,
     ylim = c(0, 1), xlab = "Time", ylab = "Proportion",
     main = paste0("SIR Epidemic (Euler)  |  β=", beta,
                   "  γ=", gamma, "  R₀=", round(beta/gamma, 2)))
lines(times, I, col = "firebrick", lwd = 2)
lines(times, R, col = "seagreen",  lwd = 2)
legend("right", legend = c("Susceptible", "Infectious", "Recovered"),
       col = c("steelblue", "firebrick", "seagreen"), lwd = 2, bty = "n")
```

::: {.callout-tip title="Try this"}
Go back to **Step 1** and try the following changes, re-running each step in order:

1. Change `gamma <- 0.5` to `gamma <- 0.2`. What does a slower recovery rate do to the epidemic peak?
2. Change `beta <- 1.5` to `beta <- 0.4`. What happens when $\beta < \gamma$? Can you explain why biologically?
3. Go back to **Step 3** and change `dt <- 0.1` to `dt <- 2.0`. What happens to the curves? This is the cost of a large step size.
:::


**Section References**

@ode_book

### Solving SIR Equations in R Using `pracma` {#sec-pracma}

The package `pracma` in R, short for "Practical Numerical Math Functions," provides a large repertoire of functions used in numerical analysis, linear algebra, numerical optimization, and differential equations [@pracma_cran]. 

::: {.callout-note}
The SIR-type models we are going to cover deal with systems of first-order ordinary differential equations.

Breaking up each word in this description, we have:

-   "First-order": This just means we are only dealing with equations involving the first derivative and not subsequent derivatives (the second, third, fourth, etc. derivative)

-   "Ordinary": The unknown function which we are trying to solve for depends only one independent variable.
:::

Although `pracma` contains many mathematical functions, we are primarily interested in `rk4sys`, a function to solve systems of differential equations using an advanced method known as the *Classic Fourth-Order Runge-Kutta Method*. This method for solving differential equations is much more complex than Euler's method but outputs solutions to a much greater accuracy. In simple terms, the Fourth-Order Runge–Kutta method estimates the value of a solution at the next point by taking a weighted average of four slope calculations, each computed at different points within the step interval [@runge_kutta_background]. 

The following table summarizes the values `rk4sys` takes in:

| **Parameter Name** | **What Does It Take In?** |
|-------------|-----------------------------------------------------------|
| `f` | A user-defined function that defines the system of differential equations to be solved. |
| `a` | A number specifying the starting point of the interval we want solutions for.  |
| `b` | A number specifying the endpoint of the interval we want solutions for. |
| `y0` | A vector specifying the initial values of the system. A system of $m$ differential equations must have a `y0` of length $m$. |
| `n` | A number specifying the step size (i.e. the number of steps that should be taken from `a` to `b`. |

The function `rk4sys` returns a matrix. When that matrix is converted to a data frame using the function `as.data.frame`, its first column provides the time points at which the SIR model was solved and subsequent columns are the solutions to the model's state variables at those times. The state variables for an SIR model are the number or proportion of individuals susceptible, infectious, and recovered at a given time.

Before we can call `rk4sys`, let's go over how to code the function to be passed into the parameter `f`. The function below is specifying a classic SIR model on the proportion of individuals in each compartment (see [Section @sec-the-classic-sir-epidemic-model]).

**Step 1: Code the model function.**

```{webr}
ModelFunc <- function(time,state){
  # Extracting the state variables
  # We have the state variables susceptible, infected, and recovered (S,I,R)
  S <- state[1]
  I <- state[2]
  R <- state[3]
  
  # Specifying the model parameters
  # We only have two parameters - the transmission and recovery rate
  # These parameters will change depending on the model
  beta <- 1.5
  gamma <- 0.5
  
  # Constructing our SIR model equations
  dS <- -(beta*I*S)
  dI <- (beta*I*S) - (gamma*I)
  dR <- (gamma*I)
  
  # Now we will return those model equations as a vector
  return(c(dS,dI,dR))
}

# Example call - Outputs the rates of change for S, I, and R given the inputs
ModelFunc(1,c(S=0.99,I=0.01,R=0))
```

**Step 2: Specify the other parameters and call `rk4sys`.**

```{webr}
library(pracma)

# Here we are specifying the start and ending points of the solution interval
start <- 0
end <- 20

# Here we are specifying the initial values to be passed into the parameter y
# Make sure values line up with the state variables in the model function
initial_vals <- c(S=0.99,I=0.01,R=0)

# Here we are specifying how many steps to take from a to b
# A common choice is to simply take b-a number of steps 
# The more steps we take, the more accurate our resulting solutions will be
step_size <- end-start

# Now we can call the function rk4sys
# We are wrapping the function ModelFunc in another function so we can pass 
output <- rk4sys(f=ModelFunc,
                 a=start,
                 b=end,
                 y0=initial_vals,
                 n=step_size)

# Converting the output matrix to a data frame and printing it
output <- as.data.frame(output)
print(output)
```

Now that we have this matrix of the solved SIR model equations are at specified times, we can plot it.

**Step 3: Plot the results.**

```{webr}
times <- output$x
S <- output$y.S
I <- output$y.I
R <- output$y.R
beta <- 1.5
gamma <- 0.5

plot(times, S, type = "l", col = "steelblue", lwd = 2,
     ylim = c(0, 1), xlab = "Time", ylab = "Proportion",
     main = paste0("SIR Epidemic (Runge-Kutta)  |  β=", beta,
                   "  γ=", gamma, "  R₀=", round(beta/gamma, 2)))
lines(times, I, col = "firebrick", lwd = 2)
lines(times, R, col = "seagreen",  lwd = 2)

legend("right", legend = c("Susceptible", "Infectious", "Recovered"),
       col = c("steelblue", "firebrick", "seagreen"), lwd = 2, bty = "n")
```


### Evaluating and Comparing Both Methods {#sec-evaluating-and-comparing-both-methods}

The following table summarizes some potential benefits and drawbacks to using Euler's method or `rk4sys` in `pracma`:

| **Solving Method** | **Potential Benefits** | **Potential Drawbacks** |
|--------------|-----------------------|------------------------------------|
| Euler's Method | \- Can be done by hand or implemented in code<br>- Simple to understand<br>- Full control over accuracy of model <br>- No external packages required | \- Low accuracy unless an extremely small step size is used<br>- Computationally inefficient for small step sizes or complex models<br>- Can be tedious to calculate by hand |
| `rk4sys` | \- Uses an advanced solving method (Fourth-Order Runge-Kutta) that has a high accuracy<br>- Handles large models with many system equations well<br>- Efficient for complex models | \- Less transparent approach; not much understanding of what is going on "under the hood"<br>- Requires learning new functions and syntax<br>- Depends on the external package `pracma`<br> - Output accuracy depends greatly on step size|

The following simulation shows the difference between the solution curves produced by Euler's method and `rk4sys` for different values of the model parameters and step size:

<iframe src="http://127.0.0.1:4570"
        width="100%"
        height="700"
        style="border:none;"></iframe>


## Finding the Transmission Rate Using MLE {#sec-formulating-transmission-rate}

*Maximum likelihood estimation*, often shorthanded as MLE, is a statistical technique that estimates the value of an unknown parameter to be that which maximizes the probability of observing real-world data from the scenario of interest. Recalling from [Section @sec-formulating-the-recovery-rate], the recovery rate is often found based on prior literature and held as a constant equal to the reciprocal of the average duration of infection. As such, for the epidemic SIR model, we generally only use MLE to estimate the value of the transmission rate $\beta$ [@parameter_estimation]. 

MLE works by maximizing the *likelihood function*. The likelihood function provides the *likelihood*, or the probability of a given piece of data $D_n$ having occurred under a particular hypothesis (or model) $H$, and is typically noted as $\mathcal{L}(H,D_i)$. In other words, the likelihood function treats the model (i.e. particular values of $\beta$) as an independent variable, or input, and outputs the probability of observing a particular piece of disease data collected. The likelihood function only provides the probability of observing a particular piece of data under different values of $\beta$, but we are generally interested in finding and maximizing the probability of observing entire sets of data not just individual observations. Assuming the entire data set is *independent* (i.e. one observation in the data set does not affect what the other observations in the data set are), we can accomplish this by multiplying the individual likelihood functions $\mathcal{L}(H,D_n)$ for every individual piece of data $D_1,D_2 \cdots , D_n$ in the data set $D$ to get the overall likelihood of the entire set of data $\mathcal{L}(H,D)$:

$$
\mathcal{L}(H,D)=\mathcal{L}(H,D_1) \times \mathcal{L}(H,D_2) \times \cdots \times \mathcal{L}(H,D_n)
$$

What this likelihood function looks like highly depends on the disease data we have available to us. Disease data often comes in two forms:

- Prevalence Count Data: Data that reports the total number of infected individuals at a time $t$. 

- Incidence Data: Data that reports the number new infected individuals over a period of time from $t$ to $t+\Delta t$

In this learning module, we will only cover the process for finding $\beta$ using MLE when we have prevalence count data, however. The MLE algorithm for prevalence count data follows these general steps:

1. Make an assumption about the distribution of the likelihood function. Oftentimes, this means assuming that every piece of observed data was randomly drawn from a Poisson distribution whose mean $\lambda$ is equal to the predicted value for the number of infectious individuals given by the SIR model at a time $t$. 

:::{.callout-note}
In this context, the Poisson distribution describes the probability of having observed a particular count of infected individuals at a time $t$ when the the average number of infectious individuals $\lambda$ is known. 
It's important to note that we are not saying the prediction from the SIR model is random but rather that each data point was drawn randomly from a distribution centered around the predicted value given by the SIR model, and that distribution is Poisson. We can imagine that for every time $t$ there is a separate Poisson distribution centered around the predicted prevalence count obtained from the SIR model from which the observed prevalence counts were drawn. 
:::

2. Set a range of plausible values for the parameter of interest ($\beta$) and iterate through all of them in tiny increments.

3. For each plausible value of $\beta$, iterate through every data point in the set and calculate its likelihood $\mathcal{L}(H,D_n)$. Multiply the likelihoods of all the data points together and store that value as $\mathcal{L}(H,D)$.

4. Repeat step 3 for every value of $\beta$ in the plausible range.

5. Now that we have a collection of likelihoods for different SIR models, given by different values of $\beta$, we should find the maximum among them and estimate the value of $\beta$ to be what provides that maximum likelihood (i.e. the maximum likelihood estimator). We can also graph the likelihoods to get a better idea of what pattern they follow and a visual representation of where the maximum occurs.


There are a few small optimizations we often make to the maximum likelihood algorithm, firstly: 

- We use *log-likelihoods* instead of raw likelihoods. 

  - Why do we do this?: The individual likelihoods $\mathcal{L}(H,D_i)$ represent the probability of observing a piece of data under a particular model, they are small numbers between $0$ and $1$ (since probability is always lies in the interval $[0,1]$). The MLE algorithm requires multiplying many of these small likelihoods together, and after a certain point (if our data set is big enough and we are multiplying enough individual likelihoods together), the computer might not be precise enough to represent such small number and simply round out our overall likelihood $\mathcal{L}(H,D)$ to be $0$! We obviously want to avoid this, so we often opt to using *log-likelihoods* instead since logarithms convert very small numbers between $0$ and $1$ into numbers larger in magnitude but negative (thus avoiding potential rounding errors). Log-likelihoods are simply obtained by taking the logarithm of the likelihood function $\mathcal{L}(H,D)$. When we do this, we must modify the way we calculate $\mathcal{L}(H,D)$, since we would no longer be multiplying the individual likelihoods $\mathcal{L}(H,D_i)$ but rather adding them. Remembering back to our properties of logarithms, we have:

$$
\log(a \times b) = \log(a) + \log(b)
$$
And from this we get:

$$
\log[\mathcal{L}(H,D)]=\log[\mathcal{L}(H,D_1) \times \cdots \times \mathcal{L}(H,D_n)]=\log[\mathcal{L}(H,D_1)] + \cdots +  \log[\mathcal{L}(H,D_n)]
$$

Taking the logarithm of the likelihood function will not change the results of MLE, making our maximum likelihood estimator for $\beta$ the same whether we use log-likelihoods or raw likelihoods. 

:::{.callout-note}
Why doesn't taking the logarithm of the likelihood function change the results of MLE?: The reason using log-likelihoods doesn't affect MLE is because the logarithm function is always increasing, so it doesn't actually change where the relative maxima of a function occur. If we have a function $f(x)$ with, say, relative maxima at $x=2,3,4$, then $\log[f(x)]$ would still have relative maxima at $x=2,3,4$. The process for MLE is dependent directly on finding where the relative maxima of the likelihood function occurs, so taking the logarithm doesn't affect its output.
:::

Including this optimization, our final modified MLE algorithm goes like so:

1. Make an assumption about the distribution of the likelihood function. Oftentimes, this means assuming that every piece of observed data was randomly drawn from a Poisson distribution whose mean $\lambda$ is equal to the predicted value for the number of infectious individuals given by the SIR model at a time $t$. 

2. Set a range of plausible values for the parameter of interest ($\beta$) and iterate through all of them in tiny increments.

3. For each plausible value of $\beta$, iterate through every data point in the set and calculate its log-likelihood $\log[\mathcal{L}(H,D_i)]$. Add the log-likelihoods of all the data points together and store that value as $\log[\mathcal{L}(H,D)]$.

4. Repeat step 3 for every value of $\beta$ in the plausible range.

5. Now that we have a collection of likelihoods for different SIR models, given by different values of $\beta$, we should find the maximum among them and estimate the value of $\beta$ to be what provides that maximum likelihood (i.e. the maximum likelihood estimator). We can also graph the likelihoods to get a better idea of what pattern they follow and a visual representation of where the maximum occurs.

This whole process can be really hard to conceptualize at first without concrete examples. We go over a few code examples of MLE coded from stratch and MLE using the `bbmle` package in R in [Sections @sec-coding-scratch] and [@sec-bbmle]. 

#### Coding An MLE Algorithm From Scratch {#sec-coding-scratch}

Suppose we have the following SIR epidemic model and we wish to use MLE to estimate the value of $\beta$:

$$
\begin{aligned}
\frac{dS}{dt} &= -\beta \left(\frac{I}{N}\right) S \\[10pt]
\frac{dI}{dt} &= \beta \left(\frac{I}{N}\right)  S - \gamma I \\[10pt]
\frac{dR}{dt} &= \gamma I
\end{aligned}
$$

For this model, $t$ is in units of days, the total size of the population we are modelling is $N=1000$ people, and the initial number of susceptible, infected, and recovered individuals is $S=999$, $I=1$, and $R=0$, respectively. 

:::{.callout-note}
These SIR equations are providing the number, not proportion, of individuals in each compartment. This is important because the prevalence count data we will be using to find $\beta$ is also a number, not a proportion. Additionally, our assumption mentioned in [Section @sec-formulating-transmission-rate] that the data follows a Poisson distribution is only valid if both our data and model are counts of people, not proportions, since the Poisson distribution is a discrete distribution only able to take on non-negative integer values.
:::

Let's also assume that we know the recovery rate to be $\gamma=0.7$ people per day based on past literature. Substituting this into our SIR equations we have:

$$
\begin{aligned}
\frac{dS}{dt} &= -\beta \left(\frac{I}{N}\right)  S \\[10pt]
\frac{dI}{dt} &= \beta \left(\frac{I}{N}\right)  S - 0.7 I \\[10pt]
\frac{dR}{dt} &= 0.7 I
\end{aligned}
$$

Now that we have our basic model equations, let's code an algorithm to find the maximum likelihood estimator for $\beta$.

**Step 1: Generate test prevalence data.**

```{webr}
library(pracma)

# Ensures that the random processes run the same every time
set.seed(123)

# Coding the SIR model function
ModelFunc <- function(time,state,parameters){
  S <- state[1]
  I <- state[2]
  R <- state[3]

  beta <- parameters["beta"]
  gamma <- parameters["gamma"]
  N <- parameters["N"]

  dS <- -(beta*I*S/N)
  dI <- (beta*I*S/N) - (gamma*I)
  dR <- (gamma*I)

  return(c(dS,dI,dR))
}

# Parameters of the SIR model from which our data will be generated
model_parameters <- c(beta = 1.2, gamma = 0.7, N = 1000)

# Number of S,I,R at the beginning of the epidemic (initial state variables)
initial_vals <- c(S = 999, I = 1, R = 0)

# Specifying how many days to generate data for
t_start <- 0
t_end <- 35
step_size <- t_end - t_start

# Solving SIR equation at specified output times
output <- rk4sys(y0=initial_vals,
                 a = t_start,
                 b = t_end,
                 f = function(t,y) ModelFunc(t,y,model_parameters),
                 n = step_size)

# Extracting the true prevalence counts
output_df <- as.data.frame(output)
I_true <- output_df$y.I

# Adding noise to the true prevalence counts (to mimic random sampling)
I_observed <- rpois(length(I_true), lambda = I_true)

# Saving the true and pseudo-sampled prevalence counts as a data frame
data <- data.frame(day = t_start:t_end,
                   prevalence_count = I_observed)

print(data)
```


:::{.callout-note}
We can actually test how accurate our estimate for $\beta$ found using MLE is by seeing how close it is to the $\beta$ used to generate the data (i.e. the value of `beta` in the named vector `model_parameters` in the code above)!
:::

Now that we have our data and a function for our SIR model called `ModelFunc`, our next step is to is to code a function to solve our SIR model for any value of $\beta$ and output what it predicts the number of infected individuals to be at various times.

**Step 2: Code a function to return predicted prevalences.**

```{webr}
# Function Inputs: Model parameters and a vector of times
# Function Outputs: Predicted prevalence counts at input times

pred <- function(parameters,t){
  initial_vals <- c(S=999,I=1,R=0)
  t_start <- 0
  t_end <- max(t)
  step_size <- t_end - t_start
  output <- rk4sys(y0=initial_vals,
                 a=t_start,
                 b=t_end,
                 f=function(t,y) ModelFunc(t,y,parameters),
                 n=step_size)
  
  # Extracting only the predicted prevalences at the input times
  output_df <- as.data.frame(output)
  prevalences <- output_df$y.I[t]

  # Ensuring there are no NaNs or out of bounds numbers in the output
  # NaNs are produced when a decimal becomes too small to represent
  prevalences[is.nan(prevalences) | prevalences < 0 ] <- 0
  return(prevalences)
}

# Example calls
pred(c(beta=1.2,gamma=0.7,N=1000),c(13,14,15))
```

Now that we have our function to output the predicted prevalence counts given by our SIR model, we need to code a function to calculate the log-likelihood of the entire data set given certain model parameters.

**Step 3: Code a function to calculate log-likelihoods given different parameter values.**

```{webr}
# Function Inputs: Named vector of model parameters and the data set
# Function Outputs: Log-likelihood of entire data set
log_likelihood <- function(parameters,data){
  times <- data$day
  predicted <- pred(parameters,times)
  
  # Note: The function dpois gives Poisson probabilities
  sum(dpois(x=data$prevalence_count,lambda=predicted,log=TRUE))
}

# Example call
log_likelihood(c(beta=1.4,gamma=0.7,N=1000),data)
log_likelihood(c(beta=2.3,gamma=0.7,N=1000),data)
```

Our final step is to code a driver function that iterates through plausible values of $\beta$, calculating the log-likelihood of the entire set of data for each, and outputs the maximum likelihood estimator for $\beta$ (i.e. the $\beta$ which produces the greatest log-likelihood).

**Step 4: Code a function to return the maximum likelihood estimator.**
```{webr}
# Function Inputs: Upper limit on the value of beta and the data set
# Function Ouputs: A plot of the log-likelihoods and the estimate for beta
mle <- function(plausible_beta,data){
  range_beta <- seq(1,plausible_beta,by=0.01)
  
  # Data frame of log-likelihoods for each beta
  all_ll <- data.frame()
  
  for (beta in range_beta){
    params <- c(beta=beta,gamma=0.7,N=1000)
    new_ll <- data.frame(beta=beta,ll=log_likelihood(params,data))
    all_ll <- rbind(all_ll,new_ll)
  }
  
  # Finding the beta that results in the greatest log-likelihood
  beta_mle <- all_ll$beta[which.max(all_ll$ll)]
  
  
  # Plotting all the log-likelihoods against the betas
  plot(all_ll$beta,
       all_ll$ll,
       type="l",xlab="beta",
       ylab="log-likelihood",
       main="Log-likelihood vs Beta")
  
  # Plotting a separate line where the maximum likelihood estimate for beta is 
  beta_mle <- all_ll$beta[which.max(all_ll$ll)]
  abline(v=beta_mle,lty=2)

  # Returning the estimate
  return(beta_mle)
}

mle(5,data)
```

::: {.callout-tip title="Try this"}
Go back to **Step 1** and try the following changes, re-running each step in order:

1. Change `model_parameters <- c(beta = 1.2, gamma = 0.7, N = 1000)` to `model_parameters <- c(beta = 1.7, gamma = 0.7, N = 1000)` and re-run the other steps. Does the maximum likelihood estimate for $\beta$ returned in **Step 4** reflect this change? What about for other values of `beta`? 
:::

This code might seem like a lot, but not to worry: there is a much easier way of doing MLE in R using the `bbmle` package! Read on to [Section @sec-bbmle] to learn how we can utilize the function `mle2` in the `bbmle` package to simplify conducting MLE in R.


**SECTION REFERENCE**

https://daphnia.ecology.uga.edu/drakelab/wp-content/uploads/2014/07/likelihood.pdf

#### MLE Using the bbmle Package in R {#sec-bbmle}

Although knowing how to code an MLE algorithm by hand is useful to first grasp the concept, in practicality it is inefficient which is why we often opt to use packages such as `bbmle` in R, which has the function `mle2` that makes it much easier.

Before we can use `bbmle` we must generate our data. This is the same code used to generate data in [Section @sec-coding-scratch]. 

**Step 1: Generate test prevalence data.**

```{webr}
library(pracma)

# Ensures that the random processes run the same every time
set.seed(123)

# SIR model function
ModelFunc <- function(time,state,parameters){
  S <- state[1]
  I <- state[2]
  R <- state[3]

  beta <- parameters["beta"]
  gamma <- parameters["gamma"]
  N <- parameters["N"]

  dS <- -(beta*I*S/N)
  dI <- (beta*I*S/N) - (gamma*I)
  dR <- (gamma*I)

  return(c(dS,dI,dR))
}

# Parameters of the SIR model from which our data will be generated
model_parameters <- c(beta = 1.2, gamma = 0.7, N = 1000)

# Number of S,I,R at the beginning of the epidemic (initial state variables)
initial_vals <- c(S = 999, I = 1, R = 0)

# Specifying how many days to generate data for
t_start <- 0
t_end <- 35
step_size <- t_end - t_start

# Solving SIR equation at specified output times
output <- rk4sys(y0=initial_vals,
                 a = t_start,
                 b = t_end,
                 f = function(t,y) ModelFunc(t,y,model_parameters),
                 n = step_size)

# Extracting the true prevalence counts
output_df <- as.data.frame(output)
I_true <- output_df$y.I

# Adding noise to the true prevalence counts (to mimic random sampling)
I_observed <- rpois(length(I_true), lambda = I_true)

# Saving the true and pseudo-sampled prevalence counts as a data frame
data <- data.frame(day = t_start:t_end,
                   prevalence_count = I_observed)

print(data)
```

Now that we have our data, let's go over the basics `mle2`. `mle2` has many arguments, which can be read up on in the (R documentation for  the `mle2` function)[@docs_bbmle_mle2], however there are only two required parameters:

- `minuslogl`: A function or formula to calculate the *negative* log-likelihood given a value for our parameter of interest ($\beta$)

- `start`: An initial guess for the value of the parameter of interest ($\beta$)

We will also make use of two other parameters to ensure our code runs smoothly:

- `method`: A string indicating what MLE algorithm method should be used. A summary of each method and how they change the MLE algorithm can be read up in the [R Documentation for the `optim` function @docs_stats_optim]. We will only make use of the method `"L-BFGS-B"`, or the *box constraint* method. This method allows for us to set a lower / upper bound on our parameter of interest $\beta$. This is useful since we know $\beta>=0$, so we can set our lower bound to be a very small number such as $0.01$ to ensure that no `NaN`s are produced when we call `mle2`. Likewise, we can set an optional upper bound on $\beta$ so we can avoid unnecessary computations if we reasonably know it to be below a certain value.

- `lower` / `upper`: These parameters are specified when using the `"L-BFGS-B"` method. These take a named vector including the lower and upper bounds of the parameter(s) of interest. Note that `lower` is a required parameter when using the `"L-BFGS-B"` method but `upper` is an optional parameter. 

**Step 2: Call `mle2` and return maximum likelihood estimate.**

```{webr}
library(bbmle)

# Function Inputs: A named vector of model Parameters and a time t
# Function Outputs: The predicted prevalence count at time t
pred <- function(parameters,t){
  initial_vals <- c(S=999,I=1,R=0)
  t_start <- 0
  t_end <- max(t)
  step_size <- t_end - t_start
  output <- rk4sys(y0=initial_vals,
                 a=t_start,
                 b=t_end,
                 f=function(t,y) ModelFunc(t,y,parameters),
                 n=step_size)
  
  # Extracting predicted prevalences
  output_df <- as.data.frame(output)
  prevalences <- output_df$y.I[t]

  # Ensuring there are no NaNs or out of bounds numbers in the output
  prevalences[is.nan(prevalences) | prevalences < 0 ] <- 0
  return(prevalences)
}
  
# Function Inputs: A named list containing a value for beta
# Function Ouputs: The log-likelihood of the data given the input beta
poisson_ll <- function(b){
  times <- data$day
  parameters <- c(beta=b,gamma=0.7,N=1000)
  predicted <- pred(parameters,times)
    # mle2 only takes in a negative log-likelihood hence the negative sign
  -sum(dpois(x=data$prevalence_count,lambda=predicted,log=TRUE))
}

# Our initial guess for what beta is
# Try making the initial guess one that is plausibly close to the true parameter
# If our guess is too far off then mle2 might return some errors
start <- list(b=2)

# Using the L-BFGS-B algorithm / method for MLE 
# Setting the lower bound to be small but positive since beta is non-negative
result <- mle2(minuslogl=poisson_ll,
                         start=start,
                         method="L-BFGS-B",
                         lower=c(b=0.01))

# Printing the result
result

# Extracting just the maximum likelihood estimate for beta
coef(result)
```

:::{.callout-note}
You'll notice that the estimate we get for $\beta$ using `mle2` is approximately equal to the one we obtain from our MLE algorithm coded by scratch (as we would expect) except that it is accurate to a far greater decimal place. This is because our MLE algorithm coded by hand is only incrementing through values of $\beta$ in steps of size $0.01$ for computational efficiency. The function `mle2` on the other hand employs much more sophisticated techniques to iterate through values of $\beta$ and calculating their  log-likelihood, making the estimate it returns much more precise.
:::

## Reproduction Numbers {#sec-reproduction-numbers}

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Define what the basic and effective reproduction number is and recall primary differences between the two.

-   Interpret the basic and effective reproduction number in context.

-   Recall the formulas for the basic and effective reproduction numbers.

-   Explain what the "threshold phenomenon" is.
:::

The reproductive number is defined as "the average number of secondary infectious cases caused by one infectious individual (before they recover or die or are otherwise not able to further transmit)" [@Handel2021_IDEMA_ch5].

The table below summarizes the two types of reproduction numbers we will focus on:

| **Name** | **Symbol** | **Interpretation** |
|-------------|-------------|-----------------------------------------------|
| Basic Reproduction Number | $R_0$ | The average number of secondary infections produced by a single infectious individual in a *completely susceptible* population. This can also be thought of as the reproduction number calculated at the beginning of an outbreak (when basically everyone is suceptible). |
| Effective Reproduction Number | $R_{e}$ | The average number of secondary infections produced by a single infectious individual in a population with a susceptible proportion equal to $\frac{S}{N}$ |

::: {.callout-note}
Some common misconceptions about $R_0$ and $R_e$ are:

-   "Must $R_0$ and $R_e$ be whole numbers because nobody can transmit the disease to, say, half a person?"

    -   No, $R_0$ and $R_e$ do not have to be whole numbers because they refer to *averages*, not the exact number of secondary infections produced by one person. An infectious person might infect nobody or tons of people but the reproduction numbers don't capture every detail just the overall picture of how many secondary infectious are produced.

    <br>

-   "Is the reproduction number a rate?"

    -   No, the reproduction number is not a rate. Take the example of HIV and SARS, which both have $R_e\approx4$. However, SARS has an extremely rapid spread while HIV is much slower spreading. One individual infected with SARS might cause 4 secondary infections within the span of a week while an individual with HIV most likely infects 4 other people within the span of a few years. $R_0$ and $R_e$ don't tell us anything about the timeframe of infections, so they are not rates.
:::

The formula for the basic reproduction number is:

$$
R_0=\frac{\beta}{\gamma}
$$

And similarly, the formula for the effective reproduction number is:

$$
R_e=\frac{\beta}{\gamma} \left( \frac{S}{N} \right) =R_0\tilde{S}
$$ These formulas should make sense, as they are multiplying the transmission rate $\beta$ by the average duration of infection $\frac{1}{\gamma}$ to obtain the average number of secondary infections by one infectious individual throughout their entire duration of infectivity.

The point where these two formulas differ is in their assumption about the proportion of susceptible individuals in the population. $R_0$ assumes a completely susceptible population, so it is multiplying the expression $\frac{\beta}{\gamma}$ by an invisible $1$. Meanwhile, $R_e$ assumes a susceptible proportion equal to $\frac{S}{N}$ hence the final expression $\frac{\beta}{\gamma}(\frac{S}{N})$.

Make sure you understand the definitions and intuition behind the formulas for $R_0$ and $R_e$. [Section @sec-the-threshold-phenomenon] on the threshold phenomenon applies the reproduction number in learning how to control the spread of infection.

**Section References**

@Handel2021_IDEMA_ch5

### The Threshold Phenomenon {#sec-the-threshold-phenomenon}

$$
\frac{d\tilde{I}}{dt} = \beta \tilde{I} \tilde{S} - \gamma \tilde{I}
$$ 

Factoring out the $\tilde{I}$, we have:

$$
\frac{d\tilde{I}}{dt} = \tilde{I}(\beta \tilde{S} - \gamma)
$$ 

If we wish to find the point at which the infection either invades or fails to, we can solve for when $\frac{d\tilde{I}}{dt}<0$ (the proportion of infectious individuals is decreasing, or the disease is "dying off") and $\frac{d\tilde{I}}{dt}>0$ (the proportion of infectious individuals is increasing, or the disease is "growing").

First, let's analyze when $\frac{d\tilde{I}}{dt}<0$:


$$
\begin{aligned}
\frac{d\tilde{I}}{dt} &< 0  && \text{Condition that the infected population is decreasing} \\[10pt]
\tilde{I}(\beta \tilde{S} - \gamma) &< 0  && \text{Substitute } \frac{d\tilde{I}}{dt} = \tilde{I}(\beta \tilde{S} - \gamma) \\[10pt]
\beta \tilde{S} - \gamma &< 0  && \text{Divide both sides by } \tilde{I} > 0 \\[10pt]
\tilde{S} &< \frac{\gamma}{\beta}  && \text{Add } \gamma \text{ to both sides, then divide by } \beta > 0
\end{aligned}
$$

Reproducing this procedure, we obtain the following similar result:

$$
\frac{d\tilde{I}}{dt} > 0 
\;\Longleftrightarrow\; 
\tilde{S} > \frac{\gamma}{\beta}
$$

From this, we can deduce that for an infection to even invade the population and start spreading, the initial proportion of susceptibles must be greater than $\frac{\gamma}{\beta}$. This result is what is specifically known as the *threshold phenomenon*, with $\frac{\gamma}{\beta}$ known as the *threshold value*. Notice that $\frac{\gamma}{\beta}$ is exactly equal to the inverse of the basic reproduction number $\frac{1}{R_0}$, which means we can also rewrite these conditions like so:

$$
\begin{aligned}
\text{Disease will not invade the population and / or spread:}
\qquad
\tilde{S} &< \frac{1}{R_0}
\\[10pt]
\text{Disease will invade the population and / or spread:}
\qquad
\tilde{S} &> \frac{1}{R_0}
\end{aligned}
$$

The simulation below let's you see the threshold phenomenon in action:

<iframe src="http://127.0.0.1:4567"
        width="100%"
        height="700"
        style="border:none;"></iframe>
    

::: {.callout-note}
Try changing the initial proportion of susceptible individuals $S(0)$ to be above and below the rounded threshold value ($\frac{\gamma}{\beta}$ ) shown. Notice that the proportion of infected individuals never increases if $S(0)<\frac{\gamma}{\beta}$ but does increase if $S(0)>\frac{\gamma}{\beta}$.
:::

Connecting this even further to reproduction numbers, we can rewrite the inequalities found above in terms of $R_e$ as follows:

$$
\begin{aligned}
\qquad
\tilde{S} &< \frac{\beta}{\gamma}
\qquad \Longleftrightarrow \qquad
R_e < 1
\\[10pt]
\qquad
\tilde{S} &> \frac{\beta}{\gamma}
\qquad \Longleftrightarrow \qquad
R_e > 1
\end{aligned}
$$

The result above is a really important one: it tells us that $R_e$ is another threshold for determining whether or not a disease will spread. Specifically, if $R_e<1$, the disease is dying off but if $R_e>1$ the disease is spreading.

This should come as no surprise though, as it can be inferred from the definition of $R_e$ itself: if every single infectious person in the population (assuming the true value for the susceptible population, unlike $R_0$ which assumes a completely naive population), on average "replaces" themselves with more than $1$ infection, the disease will spread. Moreover, the point at which $R_e$ reaches exactly $1$ marks the maximum for the infected population since it is the point at which the disease goes from spreading (number of individuals infected rising) to dying off (number of individuals infected falling).

The simulation below demonstrates how the infected population increases, decreases, and reaches its maximum at different values of $R_e$:

<iframe src="http://127.0.0.1:4568"
        width="100%"
        height="700"
        style="border:none;"></iframe>
     

::: {.callout-note}
Notice how $R_e$ starts off at its highest (when the population is almost entirely susceptible and it is equal to $R_0$), then decreases over time to be equal to $1$. At the point $R_e=1$, the proportion of infected individuals reaches a maximum. Then, as $R_e$ further decreases below $1$ the proportion of infected individuals starts decreasing as the epidemic "dies off."
:::

Try expanding the window size in the simulation above and observe what happens to $R_e$ as $t \rightarrow \infty$. Notice that $R_e$ never reaches $0$! This demonstrates another important result: for an epidemic to end, it is not necessary to completely exhaust the susceptible population and attain $R_e=0$. The epidemic will start to end its course as soon as the proportion of susceptibles dips low enough to where $R_e<1$. When this happens, the infectious individuals will, on average, no longer be "replacing" themselves with another infectious person despite there still being a non-zero population of susceptible people. If this goes on for a long enough time, the chain of transmission will break because there will be no more infectious people to spread the infection not because there were no more susceptible people to infect. This means that at the end of every epidemic, there will always be some people who were never infected and are still susceptible.

INSERT FLOW DIAGRAM THAT SHOWS EFF R AT VARIOUS FINITE STAGES AND ARROWS BETWEEN PEOPLE SPREADING THE INFECTION AND SAY THAT IF THERE IS LIKE 50 INFECTIOUS PEOPLE AND AN RE = 0.1 THEN 5 PEOPLE WILL GET INFECTED NEXT STAGE; ONCE THIS AVERAGE DIPS BELOW 1 PERSON FOR THE WHOLE INFECTIOUS POPULATION, DISEASE DIES OFF

Of course, one of our primary goals is to expedite the natural decrease of $R_e$ to be below $1$ as quickly as possible, thus reducing and eventually fully stopping the spread of infection. One of the most effective public health measures to accomplish this is vaccination [@vaccines13050479]. [Section @sec-choosing-how-many-people-to-vaccinate] answers the crucial following question: "How many vaccinated people is enough?".

**Section References**

@keeling_modeling_2008

### Choosing How Many People to Vaccinate {#sec-choosing-how-many-people-to-vaccinate}

Recall from [Section @sec-the-threshold-phenomenon] that the disease will begin to die off when $R_e$ drops below $1$. The proportion of susceptible individuals $\tilde{S}$ can be considered to be equal to $1-i$, where $i$ is the proportion of people in the population who are infectious or immune to the disease. We can rearrange the expression $R_e<1$ and solve for $i$:

<br>

$$
\begin{aligned}
R_e &< 1 && \text{Condition for disease to die off} \\[10pt]
R_0 \tilde{S} &< 1 && \text{Definition of $R_e$} \\[10pt]
R_0 (1-i) &< 1 && \text{$\tilde{S}=1-i$} \\[10pt]
i &> 1-\frac{1}{R_0} && \text{Rearranging and solving for $i$}
\end{aligned}
$$

<br>

At the beginning of the outbreak, when nearly all individuals are susceptible and there are very few infectious, the proportion of individuals immune to the disease or infectious with it $i$ can be considered approximately equal to the proportion of individuals *successfully* vaccinated against the disease. This is because, generally speaking, vaccination confers immunity, though most of the time only temporary, to a disease (https://www.who.int/news-room/feature-stories/detail/how-do-vaccines-work). Since we are analyzing a relatively small time-frame with epidemics, the temporary nature of vaccine-conferred immunity can be safely disregarded.

Notice the emphasis on the word "successfully." This is because most vaccines are not $100%$ effective; there will always be a percentage of people, though however small, that are vaccinated but can still contract the disease. Assuming a vaccine efficacy rate of $e$, or the proportion of people who are vaccinated $p$ that are truly granted immunity, the proportion of individuals successfully vaccinated is $i=ep$. We can rearrange the expression found previously to find the proportion of the population $p$ that should be vaccinated at the start of the outbreak:

<br>

$$
\begin{aligned}
i &> 1-\frac{1}{R_0} && \text{Minimum proportion of immune individuals i} \\[10pt]
ep &> 1-\frac{1}{R_0} && \text{Considering i=ep} \\[10pt]
p &> \frac{1}{e}\left(1-\frac{1}{R_0} \right) && \text{Rearranging for p}
\end{aligned}
$$

<br>

This means that, for a vaccine with an efficacy rate $e$, at the proportion of people that should be vaccinated at the start of an outbreak to prevent further spread should be at least $\frac{1}{e}(1-\frac{1}{R_0}$. Not everyone in the population must be vaccinated to stop the spread of a disease, an idea known as *herd immunity*.

However, sometimes herd immunity cannot be obtained. Take the case when $R_0=3$ and the best available vaccine has an efficacy rate of $e=0.6$ (meaning that of the people who are vaccinated, only about $60%$ of them will actually be immune and unable to contract the disease). Using the formula above, we find that the proportion of people who are vaccinated at the beginning of the outrbreak must be at least $\frac{1}{0.6}(1-\frac{1}{3})\approx1.1$. However, this is impossible: we cannot possible vaccinate more than $100%$ of the population! This means that, due to a combination of the high transmissibility of the disease and the relatively low vaccine efficacy rate, even if $100%$ of the population were to be vaccinated, there would still be enough susceptible people (i.e. people whose vaccines were not effective) for an outbreak to occur.

::: {.callout-note}
Note that the above calculations and statements are assuming ideal vaccination practices at the beginning of an outbreak when nearly all individuals are susceptible and almost none are recovered or infectious. If vaccination is implemented mid-outbreak, when the number of recovered individuals with natural immunity and infectious people are not negligible, the calculations must be modified. In general, fewer individuals will have to be vaccinated than at the beginning of an outbreak since the proportion of susceptible individuals $\tilde{S}$ will be equal to the complement of the sum of: the proportion of people who are infectious, those who have natural immunity due to recovery, and those who are successfully vaccinated.
:::

**Section References**

@Handel2021_IDEMA_ch5

## Example of the Classic Epidemic Model

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Identify examples of situations where the classic epidemic model is a useful tool for modeling.
:::

https://scholarworks.lib.csusb.edu/cgi/viewcontent.cgi?article=2232&context=etd

A disease commonly modeled using SIR-type models is measles due to its high infectivity and life-long immunity once recovered [@review_measles]. Although the mathematical modelling of measles epidemics can get very complicated with the inclusion of stochasticity (randomness) and time-series analysis [@bjornstad_measles], the example we present here is a relatively simple one that applies the concepts we discussed previously. 

**Context**

Prior to mass-vaccination campaigns, large British cities exhibited regular measles outbreaks [@bjornstad_measles]. Our scope is to model the measles disease dynamics over two year periods for various British cities using the classic epidemic SIR model.

**Data For Our Model**

The data we will be utilizing for this example is publicly avaliable through the Ottar Bjørnstad Lab at Penn State University [@bjornstad_measles_data]. The data set contains prevalence count data and annual number of births for 60 British cities from 1944 to 1966 (inclusive) as well as the median population size of each city between 1944 and 1966 (inclusive). 

Our example will only utilize the prevalence count data from 1944 to 1945 (52 weeks) and the median population size between 1944 and 1966 for the cities of Blackburn, Exeter, and Leeds, as seen in the table below:

```{r, echo=FALSE}
library(readxl)
library(DT)

data <- read_excel("../data/measles_ex_data.xlsx")
DT::datatable(data)
```

**Understanding Our Model**

The data set above contains data for three different British cities, however we are only going to walk through the formulation of an epidemic SIR model for one of them---Blackburn---using the given data which ranges from the beginning of 1944 to the end of 1945. 

When formulating a mathematical model, the first question we should ask ourselves is *what* exactly we are trying to model even looks like. Since we are simply presenting an example of the classic epidemic SIR model, the "disease flow" for measles in Blackburn could be visualized like so:


INSERT FLOW CHART OF SIR MODEL COMPARTMENTS

Putting this into words, at the beginning of 1944 we assume the proportion of susceptible, infected, and recovered individuals as $\tilde{S}(0)$, $\tilde{I}(0)$, and $\tilde{R}(0)$, respectively. Over time, the proportion of people infected with measles grows until the chain of transmission breaks since the people infected with measles at that point will, on average, not be "replacing" themselves with at least one new measles infection to keep the disease "alive." Once the chain of transmission breaks, the epidemic dies off soon after (which is to say that no people in Blackburn are infected with measles anymore). 

We can even see model process reflected in our data: in weeks 2 through 20 of 1944 there are various small introduction of measles into Blackburn, but none manage to spread further and kickstart the epidemic. This is a really important observation because it highlights the random nature of disease spread and infection. In theory, the epidemic should have started from the introduction of $2$ infected people in Blackburn in week 2 since the estimated $R_0$ for measles in England from the years 1944 to 1979 is $13.7$ to $18$ [@anderson_may_1982]. However, remembering back to [Section @sec-reproduction-numbers] $R_0$ is an *average*, not an absolute, number of secondary infections in a completely susceptible population. Even with a high average number of secondary infections, it is very possible that the people infected with measles from weeks 2 through 20 didn't manage to spread it to enough people to start the epidemic (maybe they were responsible and quarantined, or those individuals didn't interact with many people while they had measles, etc.). 

However, in week $22$ there is one new measles case that manages to successfully spread further and start the epidemic. The epidemic continues until the chain of transmission breaks sometime around week $50$ to $52$ of $1944$ and declines back down to nearly $0$ cases through most of 1945, with the exception of a few stray cases that don't manage to re-start the epidemic cycle. 

We are looking to model this measles outbreak by following the number of susceptible, infected, and recovered individuals using an epidemic SIR model, giving the following model equations:

$$
\begin{aligned}
\frac{dS}{dt} &= -\beta \left(\frac{I}{N}\right)  S \\[10pt]
\frac{dI}{dt} &= \beta \left(\frac{I}{N}\right)  S - \gamma I \\[10pt]
\frac{dR}{dt} &= \gamma I
\end{aligned}
$$

:::{.callout-note}
Since our data is given in week intervals, the rates in our model ($\beta$, $\gamma$, $\frac{dS}{dt}$,  $\frac{dI}{dt}$,  $\frac{dR}{dt}$) are in units of weeks as well.
:::

Now that we have an outline for our model, our next step is to find suitable values for the transmission rate $\beta$ and recovery rate $\gamma$. 

**Finding Our Model Parameters**

The epidemic SIR model only has two parameters, the transmission rate $\beta$ and the recovery rate $\gamma$. From past literature, it is known that the average infectious period of measles is $6$ to $7$ days, which we will estimate to be about $6.5$ days or $\frac{6.5}{7}\approx0.93$ weeks [@anderson_may_1982]. Recalling the average infectious period as equal to $\frac{1}{\gamma}$, we can obtain and estimated recovery rate of $\gamma=\frac{7}{6.5}=\frac{14}{13}$. 

Now that we have our estimate for $\gamma$, let's use the same method covered in [Section @sec-bbmle] to find the transmission rate $\beta$ using MLE:

```{webr}
library(bbmle)
library(dplyr)
library(pracma)

# Importing our prevalence count data for Blackburn
data <- read.csv("https://raw.githubusercontent.com/javirudolph/ecoSIR-modules/refs/heads/main/data/mle_example.csv")
data <- filter(data, city == "Blackburn")
counts <- data$prevalence_count
pop_size <- data$population_size[1]

# Truncating the data to be only entries after the first infection appears
first_infect <- which(counts!=0)[1]
data_trunc <- data[first_infect:nrow(data),]

# Normalizing the data to make the week the first infection appears be week 0
# This is not strictly necessary but greatly simplifies the code to come
data_trunc$week <- data_trunc$week - first_infect*2

# SIR model function
ModelFunc <- function(time,state,parameters){
  S <- state[1]
  I <- state[2]
  R <- state[3]
  
  beta <- parameters["beta"]
  gamma <- parameters["gamma"]
  N <- parameters["N"]
  
  dS <- -(beta*I*S/N)
  dI <- (beta*I*S/N) - (gamma*I)
  dR <- (gamma*I)
  
  return(c(dS,dI,dR))
}

# Outputs predicted prevalence counts
pred <- function(parameters,t){
  # S = population size - prevalence at first non-zero prevalence
  # I = first non-zero prevalence count
  # R = 0
  initial_vals <- c(S=pop_size - data_trunc$prevalence_count[1],
                    I=data_trunc$prevalence_count[1]
                    ,R=0)

  t_start <- 0
  t_end <- max(t)
  step_size <- t_end - t_start
  
  output <- rk4sys(y0=initial_vals,
                   a=t_start,
                   b=t_end,
                   f=function(t,y) ModelFunc(t,y,parameters),
                   n=step_size)

  # Extracting predicted prevalences
  output_df <- as.data.frame(output)
  prevalences <- output_df$y.I[t+1]
  
  # Ensuring there are no NaNs or out of bounds numbers in the output
  prevalences[is.nan(prevalences) | prevalences < 0 ] <- 0
  return(prevalences)
}

# Likelihood function
poisson_ll <- function(b){
  times <- data_trunc$week
  parameters <- c(beta=b,gamma=14/13,N=pop_size)
  predicted <- pred(parameters,times)
  -sum(dpois(x=counts,lambda=predicted,log=TRUE))
}

# Setting our initial guess as beta = 2
start <- list(b=4)

# Calling mle2
result <- mle2(minuslogl=poisson_ll,
               start=start,
               method="L-BFGS-B",
               lower=c(b=0.01))

# Printing the maximum likelihood estimate for beta
coef(result)
```


**Visualizing Our Model**


**Analyzing and Interpreting Our Model**

to find prop to vaccinate use efficacy rates here:

https://ir.nmu.org.ua/server/api/core/bitstreams/e4229560-2fd1-4a9f-bdeb-2c96b88fa29a/content


Include practice questions that ask to repeat process for data from other cities. 

# The Classic Endemic Model

## The Classic SIR Endemic Model

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Recall the classic endemic model's equations.

-   Differentiate the classic endemic model from the epidemic model.
:::

Recalling the information in [Section @sec-the-classic-sir-epidemic-model], the classic epidemic model assumes no demographics (births and deaths) in the population. This is because epidemics occur in such a relatively short timeframe, so the inclusion of births and deaths adds unnecessary complexity since so few will occur over this period.

However, epidemic models are not suitable for all disease; there are some diseases that do not conclude their spread sufficiently fast to neglect the births and deaths that occur during that time. This is when the SIR model with demographics, also known commonly as the classic endemic model, comes in. The classic endemic model includes birth and death rates, but makes the following key assumptions about them:

-   Every individual in the population has a natural "lifespan" of $\frac{1}{\mu}$ years, where $\mu$ is the rate at which individuals die due to natural causes

    -   $\mu$ is independent of the disease and does not represent the pathogenicity of the disease, or its ability to cause death

-   No deaths outside of natural ones dictated by the rate $\mu$ occur; in other words, there are no separate disease related deaths and $\mu$ is the crude death rate, or the death rate across people in all demographic groups and disease statuses (susceptible, infected, or recovered)

-   $\mu$ also represents the population's crude birth rate as well

    -   This ensure that the total population size does not change as time goes on; as such, $N$ is a constant in the endemic SIR just as it is in the epidemic model

-   Every individual is born into the susceptible population

    -   Although for many disease (like measles for example) newborns are born with passive immunity due to the passing down of maternal antibodies, the average age at which passive immunity is lost is much lower than the typical age of first infection in developed countries. This tells us that it is reasonable to consider all newborns as being immediately susceptible since the time to their first infection is most likely independent of their initial fading immunity at birth. This is not true of diseases that have a very small mean age of infection, however, since an infection can happen as soon as passive immunity ends.

**Section References**

@keeling_modeling_2008

::: {.callout-note}
The other assumptions made for the classic epidemic SIR apply to the endemic SIR model as well. We are just simply adding these new assumptions about the characteristics of the birth and death rates in the population. These assumptions are common but it should be noted that not all SIR models with demographics will make the same assumptions as above.
:::

The flowchart for the classic endemic model can be seen below:

```{dot}
//| fig-width: 8
//| fig-height: 5
//| fig-align: center

digraph SIRend {
  rankdir=TB;
  node [shape=box, style=rounded, fontsize=14];
  
  I [label="I"];
  R [label="R"];

  topS [label="", shape=none, width=0.01];
  bottomS [label="", shape=none, width=0.01];
  bottomI [label="", shape=none, width=0.01];
  bottomR [label="", shape=none, width=0.01];

  { rank=same; S; I; R; }
  { rank=min; topS; }
  { rank=max; bottomS; bottomI; bottomR; }

  topS -> S:n [label="  μ"];
  S -> I [label="λ", labelfontsize=12, labeldistance=2.0, labelangle=-90]
  I -> R [label="γ",  labelfontsize=12, labeldistance=2.0, labelangle=-90]

  S:s -> bottomS [label="  μ"];
  I:s -> bottomI [label="  μ"];
  R:s -> bottomR [label="  μ"];
}
```

From this flowchart, we can deduce the following equations for the number of people in each compartment according to the endemic SIR model:

$$
\begin{aligned}
\frac{dS}{dt} &= \mu-\beta \tilde{I} S - \mu S \\[10pt]
\frac{dI}{dt} &= \beta \tilde{I} S - \gamma I - \mu I\\[10pt]
\frac{dR}{dt} &= \gamma I - \mu R
\end{aligned}
$$

And just like before, we can divide every equation above by the constant population size $N$ to obtain the following equations for the proportion of individuals in each compartment:

$$
\begin{aligned}
\frac{d\tilde{S}}{dt} &= \mu-\beta \tilde{I} \tilde{S} - \mu \tilde{S} \\[10pt]
\frac{d\tilde{I}}{dt} &= \beta \tilde{I} \tilde{S} - \gamma \tilde{I} - \mu \tilde{I}\\[10pt]
\frac{d\tilde{R}}{dt} &= \gamma \tilde{I} - \mu \tilde{R}
\end{aligned}
$$

Notice that the force of infection for the endemic model is the same as the epidemic model ($\lambda=\beta \tilde{I}$).

The following sections are mostly reviews of concepts covered previously in the epidemic model. For this reason, they are mostly short sections but do cover important distinctions between the epidemic and endemic model, including how their reproduction numbers are calculated and how to solve them using `rk4sys` just to name a few.

## Formulating the Death Rate

Similar to how the recovery rate is formulated as simply the reciprocal of the average duration of infection $d$ (see [Section @sec-formulating-the-recovery-rate]), the birth / death rate is often calculated as the reciprocal of the average host lifespan (i.e. the average age to which individuals in the population survive) [@keeling_modeling_2008].

The average host lifespan, like the average duration of infection, is often obtained from past literature. 

## Solving the Endemic SIR Model - Example

The endemic SIR model can be solved using many of the same methods as the epidemic SIR model. In [Section @sec-solving-sir-equations] on solving the epidemic SIR model, we covered two main methods of doing so: Euler's method and the function `rk4sys` in the `pracma` package in R.

Both of these methods can be used to solve the endemic model as well, but we will only show an example of solving the endemic model using `rk4sys` since Euler's method is quite lengthy and is the exact same process as for the epidemic model just with different SIR equations.

Below is a complete example of using `rk4sys` to solve an endemic SIR model and plot the results:

**Step 1: Find solutions to the SIR model using `rk4sys`.**

```{webr}
library(pracma)

ModelFunc <- function(time,state){
  # Extracting the state variables
  # Same compartments as before: susceptible, infectious, and recovered (S,I,R)
  S <- state[1]
  I <- state[2]
  R <- state[3]
  
  # Specifying the model parameters
  # We now have three parameters - the transmission, recovery, and mortality rate
  # These parameters will change depending on the model
  beta <- 1.5
  gamma <- 0.3
  mu <- 0.2
  
  # Constructing our SIR model equations
  dS <- mu - (beta*I*S) - mu*S
  dI <- (beta*I*S) - (gamma*I) - mu*I
  dR <- (gamma*I) - mu*R
  
  # Now we will return those model equations as a vector
  return(c(dS,dI,dR))
}

# Start and ending points of the solution interval
start <- 0
end <- 25

# Initial values to be passed into the parameter y
initial_vals <- c(S=0.99,I=0.01,R=0)

# How many steps to take from a to b
step_size <- end-start

# Calling rk4sys
output <- rk4sys(f=ModelFunc,
                 a=start,
                 b=end,
                 y0=initial_vals,
                 n=step_size)

# Converting the output matrix to a data frame and printing it
output <- as.data.frame(output)
print(output)
```

**Step 2: Plot the results.**

```{webr}
# Plotting results
times <- output$x
S <- output$y.S
I <- output$y.I
R <- output$y.R
beta <- 1.5
gamma <- 0.3
mu <- 0.2

plot(times, S, type = "l", col = "steelblue", lwd = 2,
     ylim = c(0, 1), xlab = "Time", ylab = "Proportion",
     main = paste0("SIR Endemic (Runge-Kutta)  |  β=", beta,
                   "  γ=", gamma, "  μ=",mu, "  R₀=", round(beta/(gamma+mu), 2)))
lines(times, I, col = "firebrick", lwd = 2)
lines(times, R, col = "seagreen",  lwd = 2)

legend("right", legend = c("Susceptible", "Infectious", "Recovered"),
       col = c("steelblue", "firebrick", "seagreen"), lwd = 2, bty = "n")
```

::: {.callout-note}
Notice that the curves above seem to "even out" after a while? This is a really important distinction between the epidemic and endemic SIR model, and is explained in detail in [Section @sec-dfe-ee]. 
:::

## Reproduction Numbers

The basic and effective reproduction numbers for the endemic SIR model have the same interpretation as they do for the epidemic SIR model. Refer back to [Section @sec-reproduction-numbers] on reproduction numbers in the epidemic SIR model if you need a refresher of these definitions. 

Although they have the same interpretations before, the formulas for the basic and reproductive number are different for the endemic SIR model. 

First, let's formulate the basic reproductive number $R_0$ for the endemic SIR model. We still utilize $\beta$ as the per-capita transmission rate but instead of considering the average time an individual is infectious to be $\frac{1}{\gamma}$ (like it is for the epidemic SIR model), we consider it to be $\frac{1}{\gamma+\mu}$. On a conceptual level, this is justified because there are now two ways to leave the infectious class: recovery or death. Before in the epidemic model, there was only one way to become noninfectious---through recovery. 

Multiplying the tranmission rate $\beta$ by the average time an individual will stay infectious $\frac{1}{\gamma+\mu}$, we obtain the the basic reproduction number $R_0$ for the epidemic SIR model:

$$
R_0=\frac{\beta}{\gamma+\mu}
$$

::: {.callout-note}
This basic reproduction number for the endemic model is generally similar to, but always smaller than, the basic reproduction number for the epidemic model since the natural morality rate reduces the average time an individual is infectious (we now consider the possibility that individuals can die to natural causes while infectious, thus reducing their "infective potential"). 
:::

The effective reproduction number $R_e$ for the endemic model is quite similar to the epidemic model. It is still found by multiplying the basic reproduction number $R_0$ by the proportion of susceptible individuals in the population $\tilde{S}$ like so:

$$
R_e=R_0 \tilde{S}=\left(\frac{\beta}{\gamma+\mu} \right) \tilde{S}
$$

## Disease Free and Endemic Equilibrium {#sec-dfe-ee}

::: {.callout-tip title="Learning Objectives"}
By the end of this section, you should be able to:

-   Define what an equilibrium is the context of a system of differential equations.

-   Find the values where the disease-free and endemic equilibrium occur.

-   Recall when each equilibrium type occurs in relation to R0 and justify it based on the definition of R0.
:::

The inclusion of births in the endemic model means there is a constant "replenishing" of the susceptible population. This allows for the disease to persist in the population in the long-term, unlike the epidemic model which always ends in the disease "dying off." 

To analyze the long-term behavior of the endemic model, we start by analyzing what the model equations look like at *equilibrium*, or the point when $\frac{dS}{dt}=\frac{dI}{dt}=\frac{dR}{dt}=0$. 

::: {.callout-note}
It is important to note that equilibrium doesn't mean a lack of individuals flowing between each compartment but rather a *balanced* flow of individuals between each compartment. This means that the same number or proportion of individuals are entering and leaving each compartment at a given time, so the net change in the number or proportion of individuals in each compartment is $0$. 

We can understand this just by looking at the model equations themselves. Take the susceptible population as an example, dictated by the rate:

$$
\frac{dS}{dt} = \mu-\beta \tilde{I} S - \mu S
$$

We can see that for $\frac{dS}{dt}$ to be equal to $0$, it is not necessary that $0$ people are entering the susceptible population (i.e. being born) and $0$ people are leaving the susceptible population (i.e. getting infected). It is simply necessary that the flow rate *into* the susceptible population (given by the birth rate term \mu) is the same as the flow rate *out* of the susceptible population (given by the infection term $\beta \tilde{I} S$ and the death rate term $\mu S$). 
:::

The equilibrium of a system of differential equations is found by setting each rate of change equal to $0$ and finding the solution(s) of the resulting system:

$$
\begin{aligned}
\frac{d\tilde{S}}{dt} = 0, \quad \frac{d\tilde{I}}{dt} = 0, \quad \frac{d\tilde{R}}{dt} = 0 
& \quad && \text{Equilibrium set up} \\[10pt]
\frac{d\tilde{I}}{dt} = \beta \tilde{I} \tilde{S} - \gamma \tilde{I} - \mu \tilde{I} = 0 
& \quad && \text{Focus on the infected equation} \\[10pt]
\tilde{I}(\beta \tilde{S} - \gamma - \mu ) = 0 
& \quad && \text{Factor out } \tilde{I} \text{ to solve for equilibrium} \\[10pt]
\tilde{I}^* = 0 \quad \text{or} \quad \tilde{S}^* = \frac{\gamma + \mu}{\beta}=\frac{1}{R_0}
& \quad && \text{Two potential solutions}
\end{aligned}
$$



::: {.callout-note}
Note that above equilibrium system is solved using the endemic model equations for the proportion, not number, of individuals in each compartment. A similar procedure can be replicated to solve for the number of individuals in each compartment at the equilibrium. 

The values at which the equilibrium occur are often denoted using an asterisk ($*$) above the variable. For consistency and clarity, the values at which the equilibrium occurs for the proportion endemic model will be denoted with $\tilde{S}^*$, $\tilde{I}^*$, and $\tilde{R}^*$. Likewise, the values at which the equilibrium occurs for the number endemic model will be denoted with $S^*$, $I^*$, and $R^*$. 
:::

Notice that we actually have two possible solutions for the equilibrium, one where $\tilde{I}^*=0$ and another when $\tilde{S}^* = \frac{1}{R_0}$. We can solve for the values of the other variables at these points, starting with when $\tilde{I}^*=0$:

$$
\begin{aligned}
\frac{d\tilde{S}}{dt}=\mu - \mu \tilde{S}=0 \implies \tilde{S}^*=1
& \quad && \text{Substituting } \tilde{I}=0 \text{ into } \frac{d\tilde{S}}{dt}=0 \\[10pt]
\frac{d\tilde{R}}{dt}= - \mu \tilde{R} =0 \implies \tilde{R}^*=0
& \quad && \text{Substituting } \tilde{I}=0 \text{ into } \frac{d\tilde{R}}{dt}=0 \\[10pt]
\end{aligned}
$$

This gives us one set of values where an equilibrium can occur:

$$
(\tilde{S}^*,\tilde{I}^*,\tilde{R}^*)=(1,0,0)
$$
The other set of values corresponding to an equilibrium point can be obtained by solving for the values of $\tilde{I}^*$ and $\tilde{R}^*$ when $\tilde{S}^*=\frac{1}{R_0}$:

$$
\begin{aligned}
\frac{d\tilde{S}}{dt}=\mu - \beta \tilde{I} \left(\frac{1}{R_0} \right) -\mu \tilde{S}=0 \implies \tilde{I}^*=\frac{\mu}{\beta}(R_0-1)
& \quad && \text{Substituting } \tilde{S}=\frac{1}{R_0} \text{ into } \frac{d\tilde{S}}{dt}=0 \\[10pt]
\tilde{S}+\tilde{I}+\tilde{R}=1 \implies \tilde{R}^*=1-\frac{1}{R_0}-\frac{\mu}{\beta}(R_0-1)
& \quad && \text{Using total population equation}\\[10pt]
\end{aligned}
$$

Now we have both sets of values where an equilibrium occurs:

$$
\begin{aligned}
(\tilde{S}^*,\tilde{I}^*,\tilde{R}^*) &= (1,0,0) \\[10pt]
(\tilde{S}^*,\tilde{I}^*,\tilde{R}^*) &= \left(\frac{1}{R_0}, \frac{\mu}{\beta}(R_0-1), 1 - \frac{1}{R_0} - \frac{\mu}{\beta}(R_0-1)\right)
\end{aligned}
$$

Each of these two sets of values correspond to their own equilibrium points which have their own special names, summarized in the table below:


| **Name** | **$(\tilde{S}^*,\tilde{I}^*,\tilde{R}^*)$** | **What Is Happening At This Point?** |
|-------------|-------------|-----------------------------------------------|
| Disease-Free Equilibrium | $(1,0,0)$ | A stable point wherein the the disease has completely left the population and all recovered individuals have died due to natural causes. It can be interpreted as a population "untouched" by the disease. |
| Endemic Equilibrium | $\left(\frac{1}{R_0}, \frac{\mu}{\beta}(R_0-1), 1 - \frac{1}{R_0} - \frac{\mu}{\beta}(R_0-1)\right)$ | A stable point wherein the disease has established itself in the population and become *endemic*. A disease is endemic when "it is consistently present but limited to a particular region," which in the case of the endemic SIR model is our particular region of study [@endemic_article]. |

The next question that arises is when do these equilibrium points occur? The answer lies in the value of $R_0$: the endemic equilibrium is *asymptotically stable* when $R_0>1$, otherwise if $R_0\leq1$ then the disease-free equilibrium is stable. 

:::{.callout-note}
The stability of model systems can be a difficult concept to grasp, but in general we can think of the above statement as saying that when $R_0\leq 1$ or the initial proportion of infected individuals equals 0, all valid solution paths (solutions which exist for all positive time and are unique) approach the disease-free equilibrium given by $(\tilde{S}^*,\tilde{I}^*,\tilde{R}^*)=(1,0,0)$. Similarly, when $R_0>1$, all valid solution paths with an initial proportion of infected individuals greater than $0$ will approach the endemic equilibrium [@hethcote_math_infection].

This makes sense intuitively, as if $R_0\leq1$ the pathogen can't invade the population since every new infectious individual would only, on average, pass on the disease to one or fewer hosts. Eventually the chain of transmission would break and the disease-free equilibrium  would be approached asymptotically (over time). 
Likewise, if $R_0>1$ the pathogen can invade the population with even just the smallest introduction of infectious individuals since they will successively infect more people (who will then infect more even more people, etc.). The chain of transmission will not break either like it does in the epidemic SIR model since the population of susceptibles is constantly being "replenished" via new births, so the disease-free equilibrium is approached asymptotically. 
:::

The simulation below lets you see which equilibrium will be approached for different values of $R_0$ and initial proportion of infected individuals:

<iframe src="http://127.0.0.1:4569"
        width="100%"
        height="700"
        style="border:none;"></iframe>
     

:::{.callout-note}
Try setting the transmission rate to $1$, the recovery rate to $0.7$, and the birth / death rate to $0.4$. Notice that under these model parameters, the basic reproduction number $R_0$ is barely under $1$ ($R_0\approx0.909$). Now try changing the initial proportion of infected individuals and observe what happens to the SIR curves over time. Even for an initial infected proportion of $1$ (at the start everyone is infected), the curves still approach the disease-free equilibrium as expected! 

Now try setting the parameters to result in $R_0>1$ and observe the proportion of susceptible, infected, and recovered individuals as time progresses (you can see the exact proportions by hovering over each curve). Do these line up exactly with values at the endemic equilibrium point calculated before? 
:::

ASK JAVI: SHOULD ADD SECTION EXPLAINING USEFULNESS OF EQUILIBRIUM POINTS? CAN WE FIND ANY GOOD APPLICATION QUESTIONS FOR THEM?










